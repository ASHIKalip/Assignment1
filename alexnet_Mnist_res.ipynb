{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOEcnnUfLWGJSgc6Khp3i8d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASHIKalip/DataScience/blob/main/alexnet_Mnist_res.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0jwr0mo8mIV",
        "outputId": "e34c62f2-fd09-4d4d-8071-843d19cd803c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 27s 9ms/step - loss: 0.1873 - accuracy: 0.9410 - val_loss: 0.0627 - val_accuracy: 0.9853\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0659 - accuracy: 0.9825 - val_loss: 0.0388 - val_accuracy: 0.9897\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0547 - accuracy: 0.9858 - val_loss: 0.0546 - val_accuracy: 0.9859\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0518 - accuracy: 0.9877 - val_loss: 0.0443 - val_accuracy: 0.9883\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0435 - accuracy: 0.9885 - val_loss: 0.0410 - val_accuracy: 0.9909\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0438 - accuracy: 0.9896 - val_loss: 0.0456 - val_accuracy: 0.9881\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0352 - accuracy: 0.9918 - val_loss: 0.0290 - val_accuracy: 0.9910\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0379 - accuracy: 0.9911 - val_loss: 0.0492 - val_accuracy: 0.9877\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0403 - accuracy: 0.9914 - val_loss: 0.0543 - val_accuracy: 0.9901\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0364 - accuracy: 0.9920 - val_loss: 0.0491 - val_accuracy: 0.9911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a505e87bf10>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Corrected AlexNet-like model for MNIST\n",
        "def create_alexnet_mnist():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(64, (5, 5), activation='relu', padding='same', input_shape=(28, 28, 1)),  # Smaller kernel, same padding\n",
        "        layers.MaxPooling2D((2, 2), strides=2),  # Regular pooling with stride 2\n",
        "        layers.Conv2D(128, (5, 5), activation='relu', padding='same'),  # Adjusted kernel size and padding\n",
        "        layers.MaxPooling2D((2, 2), strides=2),\n",
        "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),  # Smaller kernel, same padding\n",
        "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),  # Smaller kernel, same padding\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2), strides=2),  # Keep max pooling stride 2\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1024, activation='relu'),  # Reduced layer size\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1024, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax'),  # Output layer for 10 classes\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "# Create and compile the model\n",
        "model = create_alexnet_mnist()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_loss, baseline_accuracy=model.evaluate(x_test, y_test)\n",
        "print(baseline_loss,baseline_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjhmb72dA8Iw",
        "outputId": "7d3dae28-b1e8-469f-c09a-38fce748c7bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0491 - accuracy: 0.9911\n",
            "0.049107328057289124 0.991100013256073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If using Colab, install the required package\n",
        "!pip install -q tensorflow-model-optimization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-FixwjR8rHv",
        "outputId": "86a00143-a03f-4933-d796-5f92ccddd08f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/242.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "# Adding pruning callbacks\n",
        "pruning_callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "    tfmot.sparsity.keras.PruningSummaries(log_dir='log')  # Optional: For visualization\n",
        "]\n",
        "\n",
        "\n",
        "# Apply a pruning wrapper to the model\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "pruning_params = {\n",
        "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
        "        initial_sparsity=0.2,  # initial sparsity level\n",
        "        final_sparsity=0.8,    # final sparsity level\n",
        "        begin_step=0,\n",
        "        end_step=2000,         # roughly corresponds to 10 epochs\n",
        "    )\n",
        "}\n",
        "\n",
        "# Apply the pruning wrapper to the original model\n",
        "pruned_model = prune_low_magnitude(create_alexnet_mnist(), **pruning_params)\n",
        "\n",
        "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the pruned model\n",
        "pruned_model.fit(    x_train,    y_train,    epochs=10,    validation_data=(x_test, y_test),    callbacks=pruning_callbacks)\n",
        "\n",
        "# Strip the pruning wrapper for better model size\n",
        "final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the final (pruned and stripped) model\n",
        "pruned_loss, pruned_accuracy = final_model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "Le_v1KlG9TFP",
        "outputId": "48e544f1-e925-4842-ffd7-78f599142711"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "   5/1875 [..............................] - ETA: 27s - loss: 2.3244 - accuracy: 0.1125    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0106s vs `on_train_batch_end` time: 0.0214s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 42s 18ms/step - loss: 0.2075 - accuracy: 0.9326 - val_loss: 0.0399 - val_accuracy: 0.9873\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0464 - accuracy: 0.9867 - val_loss: 0.0343 - val_accuracy: 0.9897\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0349 - accuracy: 0.9902 - val_loss: 0.0325 - val_accuracy: 0.9909\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 0.0246 - val_accuracy: 0.9931\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0390 - val_accuracy: 0.9880\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.0274 - val_accuracy: 0.9924\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0301 - val_accuracy: 0.9924\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.0346 - val_accuracy: 0.9921\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0409 - val_accuracy: 0.9897\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.0366 - val_accuracy: 0.9915\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fe2dd636b69a>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Evaluate the final (pruned and stripped) model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mpruned_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruned_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3981\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3983\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3984\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3985\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "pruned_loss, pruned_accuracy=final_model.evaluate(x_test, y_test)\n",
        "print(pruned_loss, pruned_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "131jxgQEAKZB",
        "outputId": "bcbcb5c4-4f0c-4a0b-e8aa-08ef58f5f00c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0366 - accuracy: 0.9915\n",
            "0.03657243773341179 0.9915000200271606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Save the original model\n",
        "model.save(\"alexnet_mnist.h5\")\n",
        "\n",
        "# Save the pruned model\n",
        "final_model.save(\"pruned_alexnet_mnist.h5\")\n",
        "\n",
        "# Get the size of the models\n",
        "original_size = os.path.getsize(\"alexnet_mnist.h5\")\n",
        "pruned_size = os.path.getsize(\"pruned_alexnet_mnist.h5\")\n",
        "\n",
        "print(f\"Baseline accuracy: {baseline_accuracy}, Baseline model size: {original_size / (1024 * 1024):.2f} MB\")\n",
        "print(f\"Pruned accuracy: {pruned_accuracy}, Pruned model size: {pruned_size / (1024 * 1024):.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-BcY9Gw9W1o",
        "outputId": "e33fea91-1619-4202-e2a1-b64a05c8554e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 0.991100013256073, Baseline model size: 41.58 MB\n",
            "Pruned accuracy: 0.9915000200271606, Pruned model size: 13.88 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the dataset is of type FLOAT32\n",
        "x_train_float32 = x_train.astype(\"float32\")\n",
        "\n",
        "# Representative dataset function for quantization calibration\n",
        "def representative_dataset_gen():\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices((x_train_float32[:100])).batch(1):\n",
        "        yield [input_value]  # Ensure FLOAT32\n"
      ],
      "metadata": {
        "id": "gg0703MXCGxy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TensorFlow Lite converter for the pruned model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "\n",
        "# Enable integer quantization with representative dataset\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.representative_dataset = representative_dataset_gen  # Ensure FLOAT32\n",
        "\n",
        "# Convert the model to TensorFlow Lite\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"pruned_alexnet_mnist.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ami1h6pnCoIm",
        "outputId": "5cbfc4d9-2a55-4728-8305-f4f150411a2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load the TFLite model\n",
        "tflite_model_path = \"pruned_alexnet_mnist.tflite\"  # Your TFLite model file\n",
        "interpreter = tf.lite.Interpreter(model_content=open(tflite_model_path, \"rb\").read())\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "# Create a test input with the expected shape and type\n",
        "# Adjust the shape and dtype based on your model\n",
        "input_shape = input_details[\"shape\"]\n",
        "input_dtype = input_details[\"dtype\"]\n",
        "test_input = np.random.random(input_shape).astype(input_dtype)  # Random input for latency check\n",
        "\n",
        "# Measure latency\n",
        "num_iterations = 100  # Number of iterations for the test\n",
        "latency_times = []\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "    # Set the input tensor\n",
        "    interpreter.set_tensor(input_details[\"index\"], test_input)\n",
        "\n",
        "    # Measure the time for a single inference\n",
        "    start_time = time.time()\n",
        "    interpreter.invoke()  # Run inference\n",
        "    end_time = time.time()\n",
        "\n",
        "    latency_times.append(end_time - start_time)\n",
        "\n",
        "# Calculate average latency\n",
        "average_latency = sum(latency_times) / num_iterations\n",
        "\n",
        "print(f\"Average latency for {num_iterations} inferences: {average_latency:.6f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0zaSPtgDIKO",
        "outputId": "5dc1888c-9919-4736-afbd-a1d4e0063ed8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average latency for 100 inferences: 0.003254 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_size = os.path.getsize(\"alexnet_mnist.h5\")\n",
        "pruned_size = os.path.getsize(\"pruned_alexnet_mnist.tflite\")\n",
        "print(f\"Baseline model size: {original_size / (1024 * 1024):.2f} MB\")\n",
        "print(f\"Pruned model size: {pruned_size / (1024 * 1024):.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdMqMb4nD92b",
        "outputId": "8e338099-3ee1-49db-ab1c-1faa8db9f5bf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model size: 41.58 MB\n",
            "Pruned model size: 3.49 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the dataset is of type FLOAT32\n",
        "x_train_float32 = x_train.astype(\"float32\")  # Convert to numpy with correct dtype\n",
        "\n",
        "# Define the representative dataset function for calibration\n",
        "def representative_dataset_gen():\n",
        "    # Using a slice of x_train as the representative dataset\n",
        "    for data in tf.data.Dataset.from_tensor_slices(x_train_float32[:100]).batch(1):\n",
        "        yield [data]  # Yield TensorFlow tensor in FLOAT32\n"
      ],
      "metadata": {
        "id": "riLBpHLcERRG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TensorFlow Lite converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Enable integer quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.representative_dataset = representative_dataset_gen  # Ensure float32 tensors\n",
        "\n",
        "# Convert the model to TensorFlow Lite\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the quantized TFLite model\n",
        "with open(\"quantized_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Quantized model saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8B7OZcZFwDH",
        "outputId": "07a9b9f9-967b-4765-9a8c-4e178ffbd26b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model saved successfully.\n"
          ]
        }
      ]
    }
  ]
}